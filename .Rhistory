runApp('C:/Users/mailson/Desktop/MLToolcredits')
# R packages
library(tidyverse)
library(caret)
library(MLmetrics)
library(stringr)
library(rpart)        # Tree / Arvore decisão
library(e1071)        # svm
library(randomForest)
# Data Set
df<- read.csv("C:/Users/mailson/Desktop/MLToolcredits/Database/Creditos.csv")
# Transformar variavel dependente em Factor
df$Creditability <- factor(df$Creditability)
# Explore data
#summary(df)
# SVM with CARET
# Set up Repeated k-fold Cross Validation
TrainCtrl1 <- trainControl(method="repeatedcv", number=10, repeats=3)
# Dividir dataset em Treino e Teste (70 / 30)
data_part <- createDataPartition(y = df$Creditability, p = 0.70, list = F)
testTrainData <- df[-data_part,] # 30% para Teste
trainTrainData <- df[data_part,] # 70% para Treino
X <- trainTrainData[,-1]           # Variaveis de entrada
y <- trainTrainData$Creditability  # Variavel resposta (saída)
# Fit the model SVM
####modelSvm <- train(X, y, method="svmLinear", trControl=TrainCtrl1, preProcess=c("center","scale"))
modelSvm <- svm(Creditability ~ ., data=trainTrainData, probability=TRUE)
# Fit the model Regressão logistica
####modelRlog <- train(X, y, method="glm", family=binomial, trControl=TrainCtrl1)
modelRlog <- glm(formula= Creditability ~ ., data=trainTrainData, family=binomial)
## Fit the model decision tree
####fitControl <- trainControl(method= "cv", number=10, savePredictions=TRUE )
####modelTree <- train(X, y, method="rpartScore", trControl=fitControl)
modelTree <- rpart(Creditability ~ ., data=trainTrainData) # , maxdepth = 5) # method = "class")
####modelTree <- rpartScore(Creditability ~ ., data=trainTrainData) # , maxdepth = 5)
## Fit the model randomForest
modelRfor <- randomForest(Creditability ~ ., data=trainTrainData)
## Fit the model decision tree GBM
#fitControl <- trainControl(method = "cv", number = 10)
#tune_Grid <-  expand.grid(interaction.depth = 2, n.trees = 500, shrinkage = 0.1, n.minobsinnode = 10)
#set.seed(825)
#modelTree <- train(Creditability ~ ., data=trainTrainData,
#                 method = "gbm", trControl = fitControl,
#                 verbose = FALSE, tuneGrid = tune_Grid)
# Teste com uma linha
testTrainData <- tail(trainTrainData,1)
#testTrainData <- head(trainTrainData,1)
####
## Previsões dos Modelos
####
# Prever a variavel resposta (dependente)
####PredSvm <- predict(modelSvm,testTrainData[,-1])
PredSvm <- predict(modelSvm, testTrainData[,-1], probability=TRUE)
PredSvm <- head(attr(PredSvm, "probabilities"))[,1]
# Prever a variavel resposta (dependente)
PredRlog <- predict(modelRlog,testTrainData[,-1], type="response")
# Prever a variavel resposta (dependente)
PredTree <- predict(modelTree,testTrainData[,-1], type= "prob")[,1]   # [,2]
# Prever a variavel resposta (dependente)
PredRfor <- predict(modelRfor, testTrainData[,-1], type="prob")[,1]
# Resultados dos Modelos
#dfR <- tibble(Modelo=c('SVM Linear','Regressão Logistica', 'Arvore Decisão'),
#              Exatidão=c(Accuracy(PredSvm, testTrainData$Creditability)*1000,Accuracy(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 ) ,
#              Especificidade=c(Specificity(PredSvm, testTrainData$Creditability)*1000,Specificity(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 ),
#              Sensibilidade=c(Sensitivity(PredSvm, testTrainData$Creditability)*1000,Sensitivity(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 )
#             )
dfR <- tibble(Modelos=c('RegressãoLogistica', 'ArvoreDecisão','SVM','RandomForest'),
Rank=c(PredRlog*1000,PredTree*1000,PredSvm*1000,PredRfor*1000)  )
dfR <- dfR %>% mutate(Rank=round(Rank,0)) %>% arrange(desc(Rank)) %>%
mutate(Icon = ifelse((Rank <= 400), c('<img src="Img_bolas_vermelha.png" height="20"></img>'),
ifelse((Rank > 400 & Rank <= 700), c('<img src="Img_bolas_laranja.png" height="20"></img>') ,
ifelse((Rank > 700), c('<img src="Img_bolas_verde.png" height="20"></img>') , "Great"
)))) %>% mutate(Crédito = ifelse((Rank <= 400), "Negado",
ifelse((Rank > 400 & Rank <= 700), "Risco",
ifelse((Rank > 700), "Aprovado" , "Great"
))))
dfR <- head(dfR,3)
runApp('C:/Users/mailson/Desktop/MLToolcredits')
library(tidyverse)
remove.packages("tidyverse", lib="~/R/win-library/3.6")
install.packages("tidyverse")
library(tidyverse)
shiny::runApp('C:/Users/mailson/Desktop/MLToolcredits')
# R packages
library(tidyverse)
library(caret)
library(MLmetrics)
library(stringr)
library(rpart)        # Tree / Arvore decisão
library(e1071)        # svm
library(randomForest)
# Data Set
df<- read.csv("C:/Users/mailson/Desktop/MLToolcredits/Database/Creditos.csv")
# Transformar variavel dependente em Factor
df$Creditability <- factor(df$Creditability)
# Explore data
#summary(df)
# SVM with CARET
# Set up Repeated k-fold Cross Validation
TrainCtrl1 <- trainControl(method="repeatedcv", number=10, repeats=3)
# Dividir dataset em Treino e Teste (70 / 30)
data_part <- createDataPartition(y = df$Creditability, p = 0.70, list = F)
testTrainData <- df[-data_part,] # 30% para Teste
trainTrainData <- df[data_part,] # 70% para Treino
X <- trainTrainData[,-1]           # Variaveis de entrada
y <- trainTrainData$Creditability  # Variavel resposta (saída)
# Fit the model SVM
####modelSvm <- train(X, y, method="svmLinear", trControl=TrainCtrl1, preProcess=c("center","scale"))
modelSvm <- svm(Creditability ~ ., data=trainTrainData, probability=TRUE)
# Fit the model Regressão logistica
####modelRlog <- train(X, y, method="glm", family=binomial, trControl=TrainCtrl1)
modelRlog <- glm(formula= Creditability ~ ., data=trainTrainData, family=binomial)
## Fit the model decision tree
####fitControl <- trainControl(method= "cv", number=10, savePredictions=TRUE )
####modelTree <- train(X, y, method="rpartScore", trControl=fitControl)
modelTree <- rpart(Creditability ~ ., data=trainTrainData) # , maxdepth = 5) # method = "class")
####modelTree <- rpartScore(Creditability ~ ., data=trainTrainData) # , maxdepth = 5)
## Fit the model randomForest
modelRfor <- randomForest(Creditability ~ ., data=trainTrainData)
## Fit the model decision tree GBM
#fitControl <- trainControl(method = "cv", number = 10)
#tune_Grid <-  expand.grid(interaction.depth = 2, n.trees = 500, shrinkage = 0.1, n.minobsinnode = 10)
#set.seed(825)
#modelTree <- train(Creditability ~ ., data=trainTrainData,
#                 method = "gbm", trControl = fitControl,
#                 verbose = FALSE, tuneGrid = tune_Grid)
# Teste com uma linha
testTrainData <- tail(trainTrainData,1)
#testTrainData <- head(trainTrainData,1)
####
## Previsões dos Modelos
####
# Prever a variavel resposta (dependente)
####PredSvm <- predict(modelSvm,testTrainData[,-1])
PredSvm <- predict(modelSvm, testTrainData[,-1], probability=TRUE)
PredSvm <- head(attr(PredSvm, "probabilities"))[,1]
# Prever a variavel resposta (dependente)
PredRlog <- predict(modelRlog,testTrainData[,-1], type="response")
# Prever a variavel resposta (dependente)
PredTree <- predict(modelTree,testTrainData[,-1], type= "prob")[,1]   # [,2]
# Prever a variavel resposta (dependente)
PredRfor <- predict(modelRfor, testTrainData[,-1], type="prob")[,1]
# Resultados dos Modelos
#dfR <- tibble(Modelo=c('SVM Linear','Regressão Logistica', 'Arvore Decisão'),
#              Exatidão=c(Accuracy(PredSvm, testTrainData$Creditability)*1000,Accuracy(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 ) ,
#              Especificidade=c(Specificity(PredSvm, testTrainData$Creditability)*1000,Specificity(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 ),
#              Sensibilidade=c(Sensitivity(PredSvm, testTrainData$Creditability)*1000,Sensitivity(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 )
#             )
dfR <- tibble(Modelos=c('RegressãoLogistica', 'ArvoreDecisão','SVM','RandomForest'),
Rank=c(PredRlog*1000,PredTree*1000,PredSvm*1000,PredRfor*1000)  )
dfR <- dfR %>% mutate(Rank=round(Rank,0)) %>% arrange(desc(Rank)) %>%
mutate(Icon = ifelse((Rank <= 400), c('<img src="Img_bolas_vermelha.png" height="20"></img>'),
ifelse((Rank > 400 & Rank <= 700), c('<img src="Img_bolas_laranja.png" height="20"></img>') ,
ifelse((Rank > 700), c('<img src="Img_bolas_verde.png" height="20"></img>') , "Great"
)))) %>% mutate(Crédito = ifelse((Rank <= 400), "Negado",
ifelse((Rank > 400 & Rank <= 700), "Risco",
ifelse((Rank > 700), "Aprovado" , "Great"
))))
dfR <- head(dfR,3)
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
testTrainData <- head(trainTrainData,1)
## Previsões dos Modelos
####
# Prever a variavel resposta (dependente)
####PredSvm <- predict(modelSvm,testTrainData[,-1])
PredSvm <- predict(modelSvm, testTrainData[,-1], probability=TRUE)
PredSvm <- head(attr(PredSvm, "probabilities"))[,1]
# Prever a variavel resposta (dependente)
PredRlog <- predict(modelRlog,testTrainData[,-1], type="response")
# Prever a variavel resposta (dependente)
PredTree <- predict(modelTree,testTrainData[,-1], type= "prob")[,1]   # [,2]
# Prever a variavel resposta (dependente)
PredRfor <- predict(modelRfor, testTrainData[,-1], type="prob")[,1]
# Resultados dos Modelos
#dfR <- tibble(Modelo=c('SVM Linear','Regressão Logistica', 'Arvore Decisão'),
#              Exatidão=c(Accuracy(PredSvm, testTrainData$Creditability)*1000,Accuracy(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 ) ,
#              Especificidade=c(Specificity(PredSvm, testTrainData$Creditability)*1000,Specificity(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 ),
#              Sensibilidade=c(Sensitivity(PredSvm, testTrainData$Creditability)*1000,Sensitivity(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 )
#             )
dfR <- tibble(Modelos=c('RegressãoLogistica', 'ArvoreDecisão','SVM','RandomForest'),
Rank=c(PredRlog*1000,PredTree*1000,PredSvm*1000,PredRfor*1000)  )
dfR <- dfR %>% mutate(Rank=round(Rank,0)) %>% arrange(desc(Rank)) %>%
mutate(Icon = ifelse((Rank <= 400), c('<img src="Img_bolas_vermelha.png" height="20"></img>'),
ifelse((Rank > 400 & Rank <= 700), c('<img src="Img_bolas_laranja.png" height="20"></img>') ,
ifelse((Rank > 700), c('<img src="Img_bolas_verde.png" height="20"></img>') , "Great"
)))) %>% mutate(Crédito = ifelse((Rank <= 400), "Negado",
ifelse((Rank > 400 & Rank <= 700), "Risco",
ifelse((Rank > 700), "Aprovado" , "Great"
))))
dfR <- head(dfR,3)
runApp('C:/Users/mailson/Desktop/MLToolcredits')
dfR$Crédito =='Aprovado'
dfR %>% filter( Crédito =='Aprovado' )
dfR %>% filter( Crédito =='Risco' )
dfR$Crédito <- 'Aprovado'
dfR %>% filter( Crédito =='Aprovado' )
dfR$Crédito <- 'Risco'
dfR %>% filter( Crédito =='Aprovado' )
dfR %>% filter( Crédito =='Risco' )
####
## Previsões dos Modelos
####
# Prever a variavel resposta (dependente)
####PredSvm <- predict(modelSvm,testTrainData[,-1])
PredSvm <- predict(modelSvm, testTrainData[,-1], probability=TRUE)
PredSvm <- head(attr(PredSvm, "probabilities"))[,1]
# Prever a variavel resposta (dependente)
PredRlog <- predict(modelRlog,testTrainData[,-1], type="response")
# Prever a variavel resposta (dependente)
PredTree <- predict(modelTree,testTrainData[,-1], type= "prob")[,1]   # [,2]
# Prever a variavel resposta (dependente)
PredRfor <- predict(modelRfor, testTrainData[,-1], type="prob")[,1]
# Resultados dos Modelos
#dfR <- tibble(Modelo=c('SVM Linear','Regressão Logistica', 'Arvore Decisão'),
#              Exatidão=c(Accuracy(PredSvm, testTrainData$Creditability)*1000,Accuracy(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 ) ,
#              Especificidade=c(Specificity(PredSvm, testTrainData$Creditability)*1000,Specificity(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 ),
#              Sensibilidade=c(Sensitivity(PredSvm, testTrainData$Creditability)*1000,Sensitivity(PredRlog, testTrainData$Creditability)*1000,Accuracy(PredTree, testTrainData$Creditability)*1000 )
#             )
dfR <- tibble(Modelos=c('RegressãoLogistica', 'ArvoreDecisão','SVM','RandomForest'),
Rank=c(PredRlog*1000,PredTree*1000,PredSvm*1000,PredRfor*1000)  )
dfR <- dfR %>% mutate(Rank=round(Rank,0)) %>% arrange(desc(Rank)) %>%
mutate(Icon = ifelse((Rank <= 400), c('<img src="Img_bolas_vermelha.png" height="20"></img>'),
ifelse((Rank > 400 & Rank <= 700), c('<img src="Img_bolas_laranja.png" height="20"></img>') ,
ifelse((Rank > 700), c('<img src="Img_bolas_verde.png" height="20"></img>') , "Great"
)))) %>% mutate(Crédito = ifelse((Rank <= 400), "Negado",
ifelse((Rank > 400 & Rank <= 700), "Risco",
ifelse((Rank > 700), "Aprovado" , "Great"
))))
dfR <- head(dfR,3)
View(testTrainData)
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
dfR <- head(dfR,1)
Vcredito <- dfR$Crédito
class(Vcredito)
Texto_credito <- c("Crédito ",dfR$Crédito)
class(Texto_credito)
Texto_credito
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
Texto_credito <- c("Crédito ",dfR$Crédito, dfR$Icon)
Texto_credito
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
Texto_credito <- c("Crédito ",dfR$Crédito, 'com', dfR$Rank , dfR$Icon)
Texto_credito
runApp('C:/Users/mailson/Desktop/MLToolcredits')
Texto_credito <- c("Crédito ",dfR$Crédito, 'com', dfR$Rank , 'Score', dfR$Icon)
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
dfR <- tibble(Modelos=c('RegressãoLogistica', 'ArvoreDecisão','SVM','RandomForest'),
Rank=c(PredRlog*1000,PredTree*1000,PredSvm*1000,PredRfor*1000)  )
dfR <- dfR %>% mutate(Rank=round(Rank,0)) %>% arrange(desc(Rank)) %>%
mutate(Icon = ifelse((Rank <= 400), c('<img src="Img_bolas_vermelha.png" height="25"></img>'),
ifelse((Rank > 400 & Rank <= 700), c('<img src="Img_bolas_laranja.png" height="25"></img>') ,
ifelse((Rank > 700), c('<img src="Img_bolas_verde.png" height="25"></img>') , "Great"
)))) %>% mutate(Crédito = ifelse((Rank <= 400), "Negado",
ifelse((Rank > 400 & Rank <= 700), "Risco",
ifelse((Rank > 700), "Aprovado" , "Great"
))))
dfR <- head(dfR,1)
Texto_credito <- c("Crédito ",dfR$Crédito, 'com', dfR$Rank , 'Score', dfR$Icon)
runApp('C:/Users/mailson/Desktop/MLToolcredits')
Accuracy(PredSvm,testTrainData$Creditability)
Accuracy(PredSvm,testTrainData)
Accuracy(PredSvm,y)
modelRlog$R
modelRlog$residuals
modelRlog$results
calc_acc = function(actual, predicted) {
mean(actual == predicted)
}
head(predict(modelRlog, newdata = testTrainData))
testTrainData$Creditability
# test acc
calc_acc(actual = testTrainData$Creditability,
predicted = predict(modelRlog, newdata = testTrainData))
# test acc
calc_acc(actual = PredRlog,
predicted = predict(modelRlog, newdata = testTrainData))
modelRlog <- train(X, y, method="glm", family=binomial, trControl=TrainCtrl1)
modelRlog$results
modelRlog$finalModel
summary(modelRlog)
head(predict(modelRlog, newdata = testTrainData))
calc_acc(actual = testTrainData$Creditability,
predicted = predict(modelRlog, newdata = testTrainData))
predict(modelRlog, newdata = testTrainData)
# get probs
head(predict(modelRlog, newdata = testTrainData, type = "prob"))
# get probs
head(predict(modelRlog, newdata = testTrainData, type = "prob"))[1]
# get probs
head(predict(modelRlog, newdata = testTrainData, type = "prob"))[0]
# get probs
head(predict(modelRlog, newdata = testTrainData, type = "prob"))[2]
modelRlog <- glm(formula= Creditability ~ ., data=trainTrainData, family=binomial)
fitted.results.cat <- ifelse(PredRlog > 0.5,"Yes","No")
fitted.results.cat<-as.factor(fitted.results.cat)
cm <- confusionMatrix(data=fitted.results.cat, reference=testTrainData$Creditability)
confusionMatrix(fitted.results.cat, testTrainData$Creditability)
testTrainData
dim(testTrainData)
class(testTrainData)
str(testTrainData)
fitted.results.cat <- ifelse(PredRlog > 0.5,"1","0")
fitted.results.cat<-as.factor(fitted.results.cat)
str(testTrainData)
confusionMatrix(fitted.results.cat, testTrainData$Creditability)
confusionMatrix(fitted.results.cat, testTrainData$Creditability)
cm <- confusionMatrix(fitted.results.cat, testTrainData$Creditability)
Accuracy<-round(cm$overall[1],2)
cm
# confusion matrix
table_mat <- table(testTrainData$Creditability, PredRlog > 0.5)
table_mat
accuracy_Test <- sum(diag(table_mat)) / sum(table_mat)
accuracy_Test
sum(table_mat)
runApp('C:/Users/mailson/Desktop/MLToolcredits')
fit = glm(vs ~ hp, data=mtcars, family=binomial)
predicted= predict(fit, newdata=mtcars, type="response")
plot(vs~hp, data=mtcars, col="red4")
lines(mtcars$hp, predicted, col="green4", lwd=2)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
plot(vs~hp, data=mtcars, col="red4")
lines(vs ~ hp, newdat, col="green4", lwd=2)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
plot(vs~hp, data=mtcars, col="red4")
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
plot(vs~hp, data=mtcars, col="red4")
lines(vs ~ hp, newdat, col="green4", lwd=2)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot(vs~hp, data=mtcars, col="red4")
lines(vs ~ hp, newdat, col="green4", lwd=2)
library(dplyr)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot(vs~hp, data=mtcars, col="red4")
lines(vs ~ hp, newdat, col="green4", lwd=2)
library(ggplot2)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot(vs~hp, data=mtcars, col="red4")
lines(vs ~ hp, newdat, col="green4", lwd=2)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot(mtcars, aes(vs, hp, colour = "red4")) + geom_point()
lines(vs ~ hp, newdat, col="green4", lwd=2)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot(mtcars, aes(hp, vs, colour = "red4")) + geom_point()
lines(hp ~ vs, newdat, col="green4", lwd=2)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot(mtcars, aes(hp, vs, colour = "red4")) + geom_point() +
geom_line(hp ~ vs, newdat, col="green4", lwd=2)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot(mtcars, aes(hp, vs, colour = "red4")) + geom_point() +
geom_line(hp ~ vs, newdat, col="green4", lwd=2)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot() +
geom_point(aes(x = hp, y= vs )) +
geom_line(aes(x = hp, y = vs, colour = "red"))
View(newdat)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot() +
geom_point(aes(x = newdat$hp, y= newdat$vs )) +
geom_line(aes(x = newdat$hp, y = newdat$vs, colour = "red"))
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot() +
geom_point(aes(x = newdat$vs, y= newdat$hp )) +
geom_line(aes(x = newdat$vs, y = newdat$hp, colour = "red"))
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot() +
geom_point(aes(x = newdat$hp, y= newdat$vs )) +
geom_line(aes(x = newdat$hp, y = newdat$vs, colour = "red"))
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot() +
geom_point(aes(x = newdat$hp, y= newdat$vs )) +
geom_line(aes(x = newdat$hp, y = newdat$vs, colour = fit))
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot() +
geom_point(aes(x = newdat$hp, y= newdat$vs )) +
geom_line(aes(x = newdat$hp, y = newdat$vs, colour = "red"))
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot() +
geom_point(aes(x = newdat$hp, y= newdat$vs )) +
geom_line(aes(x = newdat$hp, y = newdat$vs))
View(newdat)
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot() +
geom_point(aes(x = newdat$hp, y= newdat$vs )) +
geom_line(aes(x = newdat$vs, y = newdat$hp))
fit = glm(vs ~ hp, data=mtcars, family=binomial)
newdat <- data.frame(hp=seq(min(mtcars$hp), max(mtcars$hp),len=100))
newdat$vs = predict(fit, newdata=newdat, type="response")
ggplot() +
geom_point(aes(x = newdat$vs, y= newdat$hp )) +
geom_line(aes(x = newdat$vs, y = newdat$hp))
View(newdat)
grafico <- ggplot(newdat, aes(x=hp, y=vs)) + geom_point() +
geom_line(aes(x=hp, y=fit.glm$fitted), col="red")
grafico
grafico <- ggplot(newdat, aes(x=hp, y=vs)) + geom_point() +
geom_line(aes(x=hp, y=fit.fitted.values), col="red")
grafico
fit.fitted.values
fit$fitted.values
grafico <- ggplot(newdat, aes(x=hp, y=vs)) + geom_point() +
geom_line(aes(x=hp, y=fit$fitted.values), col="red")
grafico
grafico <- ggplot(newdat, aes(x=hp, y=vs)) + geom_point() +
geom_line(aes(x=hp, y=vs), col="red")
grafico
shiny::runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
install.packages(c("collapsibleTree", "tigris"))
shiny::runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
runApp('C:/Users/mailson/Desktop/MLToolcredits')
runApp('C:/Users/mailson/Desktop/mailsonsantos2020.github.io')
library(tibble)
library(tidyverse)
detach("package:tidyverse", unload = TRUE)
remove.packages("tidyverse", lib="~/R/win-library/3.6")
install.packages("tidyverse")
install.packages(c("shiny", "shinycssloaders"))
install.packages(c("shiny", "shinycssloaders"))
install.packages("shinycssloaders")
install.packages(c("shinycssloaders", "shinydashboardPlus", "shinyMobile", "shinyWidgets"))
install.packages(c("rmarkdown", "shinycssloaders", "tibble", "tidyquant", "tidyr", "tidyselect", "tidyxl", "timetk"))
install.packages("rmarkdown")
shiny::runApp()
install.packages("rmarkdown")
install.packages("data.table")
install.packages("dplyr")
install.packages("tibble")
library(tidyverse)
install.packages("DT")
install.packages("shinycssloaders")
shiny::runApp()
install.packages("htmltools")
shiny::runApp()
install.packages("leaflet.extras")
runApp()
runApp()
runApp()
runApp()
